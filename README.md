# ðŸ§  Math for Machine Learning â€“ DeepLearning.AI Specialization

This repository contains my completed labs, notes, and final project from the [Math for Machine Learning and Data Science Specialization](https://www.coursera.org/specializations/mathematics-for-machine-learning-and-data-science) by DeepLearning.AI.

Throughout the specialization, I explored the **core mathematical foundations of machine learning**, including:
- Linear Algebra
- Calculus
- Probability & Statistics
- Optimization

All code was written in **Python using NumPy**, and tested in **Jupyter/Colab environments** â€” with a final hands-on project that ties everything together.

---

## ðŸ“š Weekly Labs

| Week | Topic                                               | Notebook                                                                 |
|------|-----------------------------------------------------|--------------------------------------------------------------------------|
| 1    | NumPy Arrays Intro                                  | [Notebook](./week1_numpy_intro/introduction_to_numpy_arrays.ipynb)      |
| 1    | Solving Linear Equations                            | [Notebook](./week1_equation_solving/SolvingEquations.ipynb)             |
| 2    | Systems of Linear Equations (Elimination Method)    | [Notebook](./week2_eliminate_method/Linalg_usage_numpy.ipynb)           |
| 3    | Vectors: Norms, Dot Product, Cosine Similarity      | [Notebook](./week3_vectors/Vectors.ipynb)                                |
| 3    | Linear Transformations + Neural Network Connection  | [Notebook](./week3_linear_transformations_lab/LinearTranformationsAndNeuralNetworks.ipynb) |

---

## ðŸ§ª Final Project â€“ Face Compression with PCA

As the capstone of the Linear Algebra module, I implemented **Principal Component Analysis (PCA) from scratch using pure NumPy**, and applied it to compress and reconstruct face images from the Olivetti dataset.

ðŸ”— [View Final Project Repository â†’ Face Compression with PCA](https://github.com/your-username/face-compression-pca)

**What I built:**
- Flattened and centered high-dimensional face data
- Constructed the covariance matrix manually
- Performed eigenvalue decomposition without libraries
- Reduced dimensionality from 4096 â†’ 50
- Reconstructed images from compressed representations

This project gave me **hands-on mastery** of the concepts behind PCA, eigenvectors, covariance, and real-world data compression â€” and showed how **Linear Algebra powers machine learning pipelines**.

---

## âœ… Progress Tracker

- [x] Week 1 â€“ NumPy Arrays
- [x] Week 1 â€“ Solving Linear Equations
- [x] Week 2 â€“ Systems of Linear Equations (Elimination)
- [x] Week 3 â€“ Vectors (Norms, Dot Product, Cosine Similarity)
- [x] Week 3 â€“ Linear Transformations & Neural Networks
- [x] **Final Project â€“ PCA Face Compression (Linear Algebra Capstone)**

---

## ðŸ’¡ Goal

Build a **deep, working understanding** of the mathematical foundations that power modern machine learning and AI systems â€” and demonstrate my applied knowledge through code, projects, and real data.

---

## ðŸš€ How to Use

You can open any notebook directly in Google Colab:

- Click any `.ipynb` link above
- Replace `github.com` with `colab.research.google.com/github`
- Or manually copy the link into [Colab](https://colab.research.google.com)

---

Stay tuned â€” Iâ€™ll continue building real-world ML applications powered by strong math intuition. ðŸ”¬ðŸ“ˆ
